name: Git-Eval B Rank

on:
  push:
    branches: ["**"]
  pull_request:
    branches: [main]

jobs:
  evaluate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Read config
        id: config
        run: |
          if [ -f git-eval-config.json ]; then
            echo "language=$(jq -r '.language // empty' git-eval-config.json)" >> $GITHUB_OUTPUT
            echo "build=$(jq -r '.build // empty' git-eval-config.json)" >> $GITHUB_OUTPUT
            echo "test=$(jq -r '.test // empty' git-eval-config.json)" >> $GITHUB_OUTPUT
            echo "lint=$(jq -r '.lint // empty' git-eval-config.json)" >> $GITHUB_OUTPUT
          fi

      - name: CI checks
        id: ci
        run: |
          CI_SCORE=0
          CI_FEEDBACK=""

          # Test (10pts)
          TEST_CMD="${{ steps.config.outputs.test }}"
          if [ -n "$TEST_CMD" ]; then
            if timeout 120 bash -c "$TEST_CMD" > /tmp/test.log 2>&1; then
              CI_SCORE=$((CI_SCORE + 10))
              CI_FEEDBACK="${CI_FEEDBACK}‚úÖ „ÉÜ„Çπ„ÉàÈÄöÈÅé\n"
            else
              CI_FEEDBACK="${CI_FEEDBACK}‚ùå „ÉÜ„Çπ„ÉàÂ§±Êïó\n"
            fi
          fi

          # Lint (10pts)
          LINT_CMD="${{ steps.config.outputs.lint }}"
          if [ -n "$LINT_CMD" ]; then
            if timeout 120 bash -c "$LINT_CMD" > /tmp/lint.log 2>&1; then
              CI_SCORE=$((CI_SCORE + 10))
              CI_FEEDBACK="${CI_FEEDBACK}‚úÖ „É™„É≥„Çø„ÉºÈÄöÈÅé\n"
            else
              CI_FEEDBACK="${CI_FEEDBACK}‚ùå „É™„É≥„Çø„Éº„Ç®„É©„Éº\n"
            fi
          fi

          # Coverage check (10pts) - check if coverage report mentions percentage
          if [ -f /tmp/test.log ] && grep -oP '\d+%' /tmp/test.log | tail -1 | grep -q .; then
            COV=$(grep -oP '\d+(?=%)' /tmp/test.log | tail -1)
            if [ "${COV:-0}" -ge 60 ]; then
              CI_SCORE=$((CI_SCORE + 10))
              CI_FEEDBACK="${CI_FEEDBACK}‚úÖ „Ç´„Éê„É¨„ÉÉ„Ç∏ ${COV}%\n"
            else
              CI_FEEDBACK="${CI_FEEDBACK}‚ö†Ô∏è „Ç´„Éê„É¨„ÉÉ„Ç∏ ${COV}% (60% ‰ª•‰∏äÊé®Â•®)\n"
            fi
          fi

          echo "ci_score=$CI_SCORE" >> $GITHUB_OUTPUT
          {
            echo "ci_feedback<<CI_EOF"
            echo -e "$CI_FEEDBACK"
            echo "CI_EOF"
          } >> $GITHUB_OUTPUT

      - name: Collect source code
        id: source
        run: |
          # Collect source files for LLM evaluation
          {
            echo "code<<CODE_EOF"
            find . -path './.git' -prune -o -path './node_modules' -prune -o \
              \( -name '*.py' -o -name '*.js' -o -name '*.ts' -o -name '*.go' -o -name '*.rs' -o -name '*.java' -o -name '*.rb' \) \
              -print | head -20 | while read f; do
              echo "=== $f ==="
              head -200 "$f"
            done
            if [ -f DECISION.md ]; then
              echo "=== DECISION.md ==="
              cat DECISION.md
            fi
            echo "CODE_EOF"
          } >> $GITHUB_OUTPUT

      - name: LLM evaluation
        id: llm
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          if [ -z "$ANTHROPIC_API_KEY" ]; then
            echo "llm_score=0" >> $GITHUB_OUTPUT
            echo "llm_feedback=‚è≠Ô∏è ANTHROPIC_API_KEY „ÅåÊú™Ë®≠ÂÆö„ÅÆ„Åü„ÇÅ LLM Ë©ï‰æ°„Çí„Çπ„Ç≠„ÉÉ„Éó" >> $GITHUB_OUTPUT
            exit 0
          fi

          SOURCE_CODE="${{ steps.source.outputs.code }}"

          PROMPT="„ÅÇ„Å™„Åü„ÅØ„Ç≥„Éº„Éâ„É¨„Éì„É•„Ç¢„Éº„Åß„Åô„ÄÇ‰ª•‰∏ã„ÅÆ„Ç≥„Éº„Éâ„Çí B „É©„É≥„ÇØÔºàBuilderÔºâ„ÅÆÂü∫Ê∫ñ„ÅßË©ï‰æ°„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

          Ë©ï‰æ°Âü∫Ê∫ñÔºàÂêÑÈ†ÖÁõÆ 0„ÄúÊåáÂÆöÁÇπ „ÅßÊé°ÁÇπÔºâ:
          1. „Ç≥„Éº„Éâ„ÅÆÂèØË™≠ÊÄßÔºàÂëΩÂêç„ÉªÊßãÈÄ†Ôºâ: 0„Äú20 ÁÇπ
          2. Èñ¢ÂøÉ„ÅÆÂàÜÈõ¢„ÉªË®≠Ë®à: 0„Äú20 ÁÇπ
          3. „Ç®„É©„Éº„Éè„É≥„Éâ„É™„É≥„Ç∞: 0„Äú15 ÁÇπ
          4. „Éâ„Ç≠„É•„É°„É≥„Éà„ÅÆË≥™: 0„Äú15 ÁÇπ

          ÂøÖ„Åö‰ª•‰∏ã„ÅÆ JSON ÂΩ¢Âºè„ÅßÂõûÁ≠î„Åó„Å¶„Åè„Å†„Åï„ÅÑ:
          {\"readability\": ÁÇπÊï∞, \"design\": ÁÇπÊï∞, \"error_handling\": ÁÇπÊï∞, \"documentation\": ÁÇπÊï∞, \"feedback\": \"Êó•Êú¨Ë™û„ÅÆ„Éï„Ç£„Éº„Éâ„Éê„ÉÉ„ÇØ\"}

          „Ç≥„Éº„Éâ:
          ${SOURCE_CODE}"

          RESPONSE=$(curl -s https://api.anthropic.com/v1/messages \
            -H "x-api-key: $ANTHROPIC_API_KEY" \
            -H "anthropic-version: 2023-06-01" \
            -H "content-type: application/json" \
            -d "$(jq -n \
              --arg prompt "$PROMPT" \
              '{model: "claude-sonnet-4-20250514", max_tokens: 1024, messages: [{role: "user", content: $prompt}]}')")

          LLM_TEXT=$(echo "$RESPONSE" | jq -r '.content[0].text // empty')

          if [ -n "$LLM_TEXT" ]; then
            # Extract JSON from response
            LLM_JSON=$(echo "$LLM_TEXT" | python3 -c "
            import sys, json
            text = sys.stdin.read()
            start = text.find('{')
            if start >= 0:
                depth = 0
                for i in range(start, len(text)):
                    if text[i] == '{': depth += 1
                    elif text[i] == '}': depth -= 1
                    if depth == 0:
                        try:
                            json.loads(text[start:i+1])
                            print(text[start:i+1])
                        except: pass
                        break
            ")
            if [ -n "$LLM_JSON" ]; then
              R=$(echo "$LLM_JSON" | jq -r '.readability // 0')
              D=$(echo "$LLM_JSON" | jq -r '.design // 0')
              E=$(echo "$LLM_JSON" | jq -r '.error_handling // 0')
              DOC=$(echo "$LLM_JSON" | jq -r '.documentation // 0')
              LLM_FB=$(echo "$LLM_JSON" | jq -r '.feedback // "Ë©ï‰æ°ÂÆå‰∫Ü"')
              LLM_SCORE=$((R + D + E + DOC))
              echo "llm_score=$LLM_SCORE" >> $GITHUB_OUTPUT
              {
                echo "llm_feedback<<LLM_EOF"
                echo "üìù LLM Ë©ï‰æ°: ÂèØË™≠ÊÄß ${R}/20 | Ë®≠Ë®à ${D}/20 | „Ç®„É©„ÉºÂá¶ÁêÜ ${E}/15 | „Éâ„Ç≠„É•„É°„É≥„Éà ${DOC}/15"
                echo "$LLM_FB"
                echo "LLM_EOF"
              } >> $GITHUB_OUTPUT
            else
              echo "llm_score=0" >> $GITHUB_OUTPUT
              echo "llm_feedback=‚ö†Ô∏è LLM „ÅÆÂøúÁ≠î„ÇíËß£Êûê„Åß„Åç„Åæ„Åõ„Çì„Åß„Åó„Åü" >> $GITHUB_OUTPUT
            fi
          else
            echo "llm_score=0" >> $GITHUB_OUTPUT
            echo "llm_feedback=‚ö†Ô∏è LLM API „Ç®„É©„Éº" >> $GITHUB_OUTPUT
          fi

      - name: Send results to Git-Eval
        if: always()
        env:
          WEBHOOK_SECRET: ${{ secrets.GIT_EVAL_SECRET }}
          WEBHOOK_URL: ${{ secrets.GIT_EVAL_URL }}
        run: |
          if [ -z "$WEBHOOK_URL" ] || [ -z "$WEBHOOK_SECRET" ]; then
            echo "Webhook not configured, skipping"
            exit 0
          fi

          CI_SCORE=${{ steps.ci.outputs.ci_score }}
          LLM_SCORE=${{ steps.llm.outputs.llm_score }}
          TOTAL=$((CI_SCORE + LLM_SCORE))

          FEEDBACK="„ÄêCI/CD „ÉÅ„Çß„ÉÉ„ÇØ„Äë\n${{ steps.ci.outputs.ci_feedback }}\n„ÄêLLM Ë©ï‰æ°„Äë\n${{ steps.llm.outputs.llm_feedback }}\n\nÂêàË®à„Çπ„Ç≥„Ç¢: ${TOTAL}/100"

          BODY=$(jq -n \
            --arg user "${{ github.actor }}" \
            --argjson score "$TOTAL" \
            --arg feedback "$FEEDBACK" \
            '{github_username: $user, score: $score, feedback: $feedback}')

          SIG=$(echo -n "$BODY" | openssl dgst -sha256 -hmac "$WEBHOOK_SECRET" | sed 's/^.* //')

          curl -sf -X POST "${WEBHOOK_URL}/webhook/eval" \
            -H "Content-Type: application/json" \
            -H "X-Signature-256: sha256=${SIG}" \
            -d "$BODY"
